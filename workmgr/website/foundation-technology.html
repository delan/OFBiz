<html>
<head>
<title>Open For Business Foundation Technology</title>
</head>

<body>

<h2 align="center">The Open For Business Project: Foundation Technology</h2>

<br>Written By: David E. Jones
<br>Email: <a href="mailto:jonesde@ofbiz.org">jonesde@ofbiz.org</a>
<br>Open For Business Site: <a href="http://www.ofbiz.org/">http://www.ofbiz.org</a>
<br>
<A href="http://sf.net/projects/ofbiz"> <IMG src="http://sourceforge.net/sflogo.php?group_id=27173" width="88" height="31" border="0" alt="SourceForge Logo"></A> 
<br>
Founders and Lead Architects: David E. Jones &amp; Andy Zeneski <br>
Last Updated: August 20, 2001 <br>
<hr>
<h3 align="left"><a name="Table of Contents">Table of Contents</a></h3>
<ul>
  <li><a href="#Introduction">Introduction</a></li>
  <li><a href="#Common Tool Components">Common Tool Components</a>
    <ul>
      <li><a href="#Entity Engine">Entity Engine</a></li>
      <li><a href="#Rules">Rules</a></li>
      <li><a href="#Workflow">Workflow</a></li>
      <li><a href="#Constraint Based Optimization">Constraint Based Optimization</a></li>
      <li><a href="#Data Analysis">Data Analysis</a></li>
      <li><a href="#Content Management">Content Management</a></li>
      <li><a href="#Knowledge Management">Knowledge Management</a></li>
    </ul>
  </li>
  <li><a href="#Basic Technology Components">Basic Technology Components</a>
    <ul>
      <li><a href="#Foundation Technology">Foundation Technology</a></li>
      <li><a href="#Security">Security</a></li>
      <li><a href="#Human Communication">Human Communication</a></li>
      <li><a href="#Integration &amp; Connection">Integration &amp; Connection</a></li>
      <li><a href="#Development Tools">Development Tools</a></li>
      <li><a href="#Quality Assurance">Quality Assurance</a></li>
    </ul>
  </li>
</ul>
<hr>
<h3><a name="Introduction">Introduction</a></h3>
<P>This document describes the two lower layers of the Architecture Model,
found on the <a href="architecture-overview.html">Architecture Overview page</a>.&nbsp;
The foundation technology consists of the the Common Tool Components, and the
Basic Technology Components found in that diagram.&nbsp; The Common Application
Components and Vertical Applications are built on top of this layer, and use
these services to simplify implementation and provide a consistent way of doing
things.</P>
<P>The Vertical Applications use data and logic defined in the Common
Application Components layer and built on and around them to apply them to
different business processes.&nbsp; The data underneath is shared so that no
synchronization or integration is necessary between vertical applications.</P>
<P>  These foundation components are often available as separate 
products, or may be included in a larger package.  Sometimes they are 
integrated tightly with a vertical application or other foundation components and hidden from the end user and/or implementer, 
this is something we want to avoid.&nbsp; We want to develop these components so
that they can be used in any application and somewhat independent of one
another, although certain dependencies are necessary and a good idea.&nbsp; For
instance, the Workflow engine will use the Rules engine as well as other logic
mechanisms, and the Content Management will use the Workflow engine.&nbsp; The
Data Analysis tool will also use the Rules engine, but in a different way, it
will analyze data for trends and create rules based on the trends for marketing,
pricing, or other rules driven user facing systems.</P>
<P>So, the larger system should 
be made of these components, as well as components that do more specialized 
tasks.   Where possible functionality in the system should be implemented 
as a set of rules, reports, workflows and interfaces to content management 
and data analysis services.&nbsp;</P>
<hr>
<h3><a name="Common Tool Components">Common Tool Components</a></h3>
<hr>
<h4><a name="Entity Engine">Entity Engine</a></h4>
<p>The Open For Business Entity Engine has evolved over the course of the
project. It was originally created as a code generator that was entity specific
using an evolving set of templates to provide functionality based on entity
definitions. The newest evolution of the Entity Engine is a fully dynamic
attribute based engine where one set of code handles the entity management and
persistence for all of the entities defined in the system.</p>
<p>To understand this better imagine all of the code that might be generated by
the code generator for each specific entity and imagine that code being
rewritten to work for any entity definition that might occur. This is what the
current entity engine does. The functionality of this engine can be supplemented
by the code generator, but can generally be used alone. The advantage to using
fully dynamic code like this is that maintenance is much simpler and management
of entities in general can be enhanced. Adding a field to an entity is now a
five minute task (or a 30 second task if you don't do any testing) instead of
what used to take at least fifteen to twenty minutes, assuming no code merging
needed to take place.</p>
<p>Another advantage of the Entity Engine as it currently stands is that it can
be used for persistence of entities either through an Entity EJB or directly to
the database through JDBC using the same API. The only difference between the
two is that you get a different Helper class depending on the type of
persistence you want. This is accomplished using shared Helper and Value Object
definitions.</p>
<p>The Entity Engine lives in the Core module of ofbiz along with the Servlet
Controller and other useful tools there. The package name is
org.ofbiz.core.entity, with a sub-package called model that contains the code to
model entities and read the XML entity definition files.</p>
<p>For more information on the Entity Engine, see the <a href="core/docs/entity.html">Entity
Engine documentation</a>.</p>
<h5>Entity Code Generator</h5>
<p>The purpose of the Entity Code Generator is to automate the creation of code
that handles data from a relational database.&nbsp; One approach to this is
problem is to create a set of data management tools that has a data descriptor
language to define what the tools should do with the data. This general approach
can be very good for development speed in some circumstances, but runs slowly
and it is difficult to customize the behavior for a single data entity.</p>
<p>The approach of the Entity Code Generator is to automate the creation, but
not the maintenance of the entity management code.&nbsp; The value add comes in
the initial generation of code for everything from the database to the web based
user interface.&nbsp; Customizations for handling entities in non-default ways
are done in plain Java (J2EE) rather than working through the data management
tool.&nbsp; In other words, the code is generated once and either used as is or
customized for a given type of data.&nbsp; If it is customized, changes to the
data model cannot be incorporated by simply regenerating the code and copying on
top of the old customized code.&nbsp; Instead, it should be saved in a different
file and a merge tool should be used to put the new generated code in while
maintaining the customizations to the old generated code.</p>
<p>The Entity Code Generator uses a free publicly available and well know
templating engine called JSP.&nbsp; All of the templates for the generated code
are simple Java Server Pages. Because of this they can be easily customized by
anyone familiar with JSPs. These are also examples of how to generate many type
of code from JSPs including SQL, Java, other JSPs, and XML.</p>
<p>The Entity Code Generator creates code from the templates based on a data
definition written in XML.&nbsp; The XML tags used to describe the entities
mainly come from the standard ejb-jar.xml deployment descriptor so that they
will be easy to learn and use. From the data description the following can be
generated:</p>
<ol>
  <li>SQL to create a relational database table</li>
  <li>All Entity EJB Java code (Remote Interface, Home Interface, Bean, Primary
    Key Class)</li>
  <li>EJB Deployment Descriptors (the standard ejb-jar.xml; jaws.xml &amp;
    jboss.xml for JBoss, others done easily)</li>
  <li>A Value class and a Helper class (see description below)</li>
  <li>A web event handler to update the entity (see description below)</li>
  <li>JSPs to Find, Update and View the entity</li>
</ol>
<p>The last three items (4,5,6) are extensions built on top of the J2EE standard
which implement best practices in J2EE application design and provide scalable
and efficient ways of interacting with the entity data. The architecture of the
Open For Business Project is implemented and standardized through these last
three items.</p>
<p>Value and Helper classes contain most of the logic needed for working with an
Entity Bean. The Value class is essentially an implementation of the Remote
Interface of the Entity Bean. It is used in the same way that the Remote
Interface is used, and in fact implements the remote interface to insure they
stay consistent. Because of the way it is designed and because of how it is used
be the Helper class, it offers many advantages but the details of those are
handled automatically. It acts as a container for the data so that the entity
data can be passed&nbsp; all at once in a single EJB call. Data reads come
directly from the Value object while writes update the state of the Value object
as well as the actual Entity Bean, which the Value object keeps a reference
of.&nbsp; Because of this these Value objects can be cached locally in a servlet
providing the fastest possible access to data, while still being able to use it
for writing.</p>
<p>The Helper class is a proxy for the Remote Interface, but does not implement
it.&nbsp; It knows how to get the Remote Interface from JNDI and keeps a copy of
the Remote Interface so that finds can be done more quickly, and provides
methods to handle the details of calling methods on the Remote Interface so that
they can be used more easily and consistently.&nbsp; The Helper object is a
static one with all methods and data defined as static.&nbsp; It is shared by
all and never needs to be instantiated.&nbsp; It also adds a number of methods
to make working with entities easier like a removeBy method for every findBy
method.&nbsp; For entities that need an automatically generated key the create
method of the Helper is the place where that should go.&nbsp; When caching is
desired, the Helper manages the details of the cache using a generic cache
object.</p>
<p>The web event handler addresses one common problem with JSPs: where do you
put the business logic?&nbsp; JSPs are an excellent place to put display logic,
but all other logic should stay outside of the JSPs.&nbsp; The place for this
other logic is in a web event handler. Web events are called by passing an event
argument specifying which event to call to any JSP that uses the event handler
(which should be all JSPs in a project).&nbsp; The JSPs call the web event
handler through a custom tag. The event handler also manages basic security and
allows the page designer to specify if a user must be logged in to view the
page.&nbsp; If the user is not logged in, the web event handler will send a
login page, but will remember which page the user wanted to go to with
parameters (including form parameters) and all.</p>
<p>The web event handler that is automatically generated for an entity can
create, update or delete the entity.&nbsp; It handles the conversions from
strings to whatever type of data each member is, and then calls an update
function in the Helper.&nbsp; The update function in the Helper handles null
values by not updating them, but instead leaving them as is, and does an update
of the entire entity in one EJB call. Error checking can be added to the event
handler which can return the user to the data entry page and display errors on
that page, maintaining the data that was entered.</p>
<p>This is the basic data entity management architecture for the Open For
Business Project.&nbsp; Business Logic can be written in Java, but there are
other tools in the project for helping out with making the creation and
maintenance of Business Logic.</p>
<hr>
<h4><a name="Rules">Rules</a></h4>
<P>This 
component is a high level way of implementing functionality and interacting 
with data in the system.  Rules may replace the implementations of features 
normally implemented in a programming or scripting language and provide 
a value add in that they are easier to learn and work with and provide 
an automated way of simplifying complex tasks.&nbsp;
</P>
<P>Rules are used in groups or sets.  
Groups of rules are applied in specific circumstances, but the order 
of the execution of the rules does not have to be maintained by the 
user of the system, the rules engine does it automatically using inferencing&nbsp;
techniques.  Rules engines 
are useful for price calculation, business requirements checking, general 
personalization and content selection and other conditional tasks.</P>
<h5><B>Rules 
Editor/Creator</B></h5>
<P>There 
should be two types of rule editing or creating tools.  The first is 
for manual creation of rules, and editing of current rules.  There should 
be a tool that can not only create all types of rules, but generically 
edit all types.&nbsp;</P>
<P>&nbsp;The second type of rule creation 
and editing software is task specific and can be specialized for whatever purpose, and 
automated to any extent.&nbsp; Rules may be created automatically because sometimes data mining or
other application specific tools create 
rules for use in their domains.</P>
<h5><B>Rules 
Execution Engine</B></h5>
<P>Once 
a set of rules has been created, a rules execution engine should be 
available for use at any time during a program’s execution.  The rules 
execution engine must be integrated with the rest of the program to 
some extent or have some other way of reading from and writing to program 
data, and causing the execution of certain operations in the program.  
A log should be maintained, or some other mechanism, to determine which 
rules influenced a certain outcome.  The rule execution engine should 
be able to pool resources, as with many other resources in an application 
server, to provide better response times and avoid continual re-creation 
of rules engine instances.</P>
<hr>
<h4><a name="Workflow">Workflow</a></h4>
<P>A 
workflow engine is like a rules engine in that it moves functionality 
from the lower level code to high level structures and relationships 
that non-technical people can work with.  Workflows are the high level 
procedural structure behind complex and potentially varying operations.  
Workflows are useful for order processing pipelines, marketing campaign 
management procedures, sales procedures, manufacturing processes and other procedural tasks.&nbsp;
A workflow engine maintains its state persistently and can handle procedures
that require human intervention and communication with other systems, even when
there is potentially a long waiting time between when a task is started and
completed.
</P>
<P>  A workflow basically has a number if states, with 
rules and activities for state transitions. The workflow engine should be able
to use the rules engine, scripting languages or Java calls to perform actions or
make flow decisions.</P>
<h5><B>Workflow 
Editor/Modeler</B></h5>
<P>Just 
as with the rules editors, workflow editors or modelers also fall into 
the two categories of very general, and specific task oriented.  A general 
editor should be included in addition to a number of specific task or 
problem associated editors, such as one for modeling an order pipeline, 
one for setting up content creation and management procedures, one for 
setting up the flow of event for a sales process or a marketing campaign, 
and so forth.</P>
<h5><B>Workflow 
Execution Engine</B></h5>
<P>The 
workflow execution engine has the same issues as the rules execution 
engine as far as communication, or integration, with the application 
that uses it is concerned.</P>
<hr>
<h4><a name="Constraint Based Optimization">Constraint Based Optimization</a></h4>
<P>Constraints and enumeration are like rules in that they are another way of
modeling a problem.&nbsp; Certain problems are suited better to a rules engine,
and other problems are suited much better to a constraint engine.</P>
<P>Constraint Based Optimization tools simplify the general task of taking a
large set of possibilities and reducing that set to only those that conform to
the constraints specified.&nbsp; After removing all possibilities that break the
constraints, the set can further be reduced by applying a metric to choose the
best ones.&nbsp; When the number of possibilities is large, it is not feasible
to create the entire set of possibilities and reduce them, instead a
search/decision tree is made and traversed searching for a possibility that
confirms to all constraints.&nbsp; This can produce a legal result quickly, and
then be left to continue searching for a better result as defined by the
metrics.</P>
<P>Possibility sets are defined by defining variable, and then enumerating the
possible values for each variable.&nbsp; When the variable are combined, the
possibility set is created where each combination of values for the variables is
on possibility.&nbsp; Constraints are used to declare that combinations of
values or specific values are required or not allowed.</P>
<P>This technique can be used to model many problems, and find valid and optimal
solutions.&nbsp; Example applications include automatic manufacture pipeline
planning, truck scheduling and route planning, airport gate assignment,
configuration of products or services, and many others.</P>
<P>Constraints can be automatically extracted from data analysis, or implied by
data structures.&nbsp; They can be written by hand and changed and applied in
real time.&nbsp; Constraints and enumeration of states can be also used to
create workflows automatically, and provide automated real-time decision making
and workflow reconfiguration.</P>
<hr>
<h4><a name="Data Analysis">Data 
Analysis</a></h4>
<h5>Data 
Warehousing</h5>
<ul>
  <li>Extraction, 
Transformation &amp; Loading (ETL)</li>
  <li>Input 
Data Cleansing</li>
  <li>Semantic 
Transformation of Input Sources</li>
  <li>Relational 
Data Warehouse</li>
  <li>OLAP 
Multi-dimensional Warehouse</li>
</ul>
<h5><B>Statistical 
Analysis</B></h5>
<P>Apply 
statistical methods to reduce a large amount of data to a simpler pattern, 
usually expressed as a formula or graph or set of constraints, in order to make it more
understandable by humans.  
Advanced forms of statistical analysis such as regression, factor, correlation 
or cluster analysis are sometimes used as the basis for data mining 
techniques.</P>
<h5><B>Data 
Mining</B></h5>
<P>Described 
as “the non-trivial process of identifying valid, novel, potentially 
useful, and ultimately understandable patterns in data” (Fayyed, Piatesky-Shapiro, 
Smyth).  &nbsp;</P>
<P>“It is the army of analysts 
we could not afford in the OLAP world, sifting through all the billions 
of possible patterns, looking for significant relationships which give 
us knowledge to act” (Flanagan and Safdie).&nbsp;</P>
<P>“The significant problems we 
face cannot be solved by the same level of thinking that created them” 
(Albert Einstein).</P>
<H5><B><I>Deduction</I></B></H5>
<P>Create 
additional attributes based on existing attributes and rules, constraints, neural 
networks, or other forms of generalization or of describing patterns.  
Collaborative filtering is a form of this type of data mining that uses 
existing data and static rules to deduce new attributes or categories..</P>
<H5><B><I>Induction, 
abstraction </I></B></H5>
<P>Create 
generalizations from attributes and patterns that describe those attributes 
and patterns.  The generalizations can be represented as rules, constraints, neural 
networks, or other pattern descriptors.  The patterns may also be used 
to create structure, as in clustering or sequencing.</P>
<H6><B>Clustering, 
segmentation, affinity</B></H6>
<P>Automatically 
group or segment elements by attributes or patterns.  Association is a variation on this where 
connections or associations are made between entity pairs.</P>
<H6><B>Sequencing</B></H6>
<P>Create 
a linear ordering of elements according to abstract patterns or rules.</P>
<H6><B>Rule &amp; Constraint Generation</B></H6>
<P>Create 
rules or constraints that describe attributes and patterns in the data.  These rules
and constraints can be used later for deduction or for driving operational flows, as 
is often done with personalization.</P>
<H6><B>Neural 
Network Generation</B></H6>
<P>Create 
neural networks that describe a data point or a set of data points.  
This process is sometimes known as training the neural network.  These 
neural networks can later be used to compare other data to the data 
they describe.  This is done by using the other data as inputs to the 
neural network, and getting a result out which numerically describes 
how related they are.  Neural networks can represent conceptual structures 
without the need for creating explicit definitions or structures.</P>
<h5><B>Query 
&amp; Reporting</B></h5>
<P>The 
reporting tool provides for the visualization and presentation of data 
from raw sources or from the output of a data analysis procedure.  The 
reporting tool may do some data analysis, especially statistical analysis, 
in order to create the visual elements, but it is not necessary for 
it to address anything more complex.  It primarily simplifies the query 
and presentation process.&nbsp;</P>
<P>As part of the larger system, 
the reporting tool should be loosely coupled to each high level functional 
component.  Each high level component should have a set of reports that 
exist in the standard reporting tool format and that are customizable 
through standard and specialized tools by the end user, and where necessary 
by a technician internal or external to the company.  The reporting 
tool should support a flexible data import and transformation interface 
that supports various databases and flat files used in the system, and has utilities to 
support and transform custom database schema and file formats.&nbsp;
</P>
<P>Ideally the reporting tool 
would be a J2EE application with an EJB interface to data sources, in 
addition to other custom interfaces that could be coded in Java, which 
would allow access to COM, CORBA and other component interfaces.</P>
<h5><B>Online 
Analytical Processing – Multi-dimensional</B></h5>
<P>View 
subsets, or sub-cubes, of multi-dimensional natured data to manually 
find patterns or trends.  This is essentially an advanced query and 
reporting tool that creates an information layer between the data and 
the user and allows the user a more customized view of the data.  Note 
that this is different than statistical analysis because often more 
information is presented to the user and not less, but only a specified 
subset at a time.  This may include results from more standard statistical 
analysis.</P>
<h5><B>Closed 
Loop Analysis</B></h5>
<P>The 
results of data analysis are either automatically sent back to the operating
model, or translated/interpreted by a human and changes are made to 
the operating model.  The new data from operation based on that model is then analyzed 
in light of these changes.&nbsp; In other words rules, constraints, attributes
and other information is created from analysis, and then used in the business
operations.&nbsp; Closed Loop Analysis is used to measure the effectiveness of
the changes to the operating model.</P>
<hr>
<h4><a name="Content Management">Content 
Management</a></h4>
<h5><B>Content 
Repository and Version Control System</B></h5>
<P>The 
main purpose of a content management system is to provide a place to 
store content and manage it as it changes.  This includes maintenance 
of revision histories, current versions, and so forth.  The system should 
be able to deal with many types of content, including: various forms 
or plain text; standard word processing, spreadsheet, and presentation 
files; various image formats; relational and object oriented database 
information. The highest priority among these different file types is plain
text. Many of the other types can be stored in a binary format very simply but
require a lot more work to do revision control of them.&nbsp; Tools should be included to merge different revisions 
of the data.</P>
<h5><B>Meta-data 
and Structure Management and Storage</B></h5>
<P>The 
content management system should be able to store and manage all meta-data 
corresponding to the data or content it manages.  It should also have 
facilities for managing the structure of the content in an hierarchy, abstract
relational graph, or a sequence.  Manual tools should be provided for editing the 
meta-data and structure information.  The structure information and 
meta-data should also be available to external programs for analysis 
and modification.</P>
<h5><B>Content 
Workflow Tool</B></h5>
<P>The 
content workflow tool is a generalized tool to manage tasks for individuals 
based on workflows defined for each piece or set of content.  This can 
be used for a change request &amp; bug management system, or complex content creation tasks, and for quality control procedures once the content 
has been created.  The workflow tool here would be the workflow tool listed
above with some customizations specific to content management.</P>
<h5><B>Content 
Deployment</B></h5>
<P>Deployment 
tools should be included to facilitate the deployment of data and meta-data 
controlled by the content management system, and outside the content 
management system.  The deployment tool should have facilities to call 
scripts or other programs as part of it’s workflow so that manual steps 
can be completely removed from the process.</P>
<hr>
<h4><a name="Knowledge Management">Knowledge 
Management</a></h4>
<h5><B>Automated 
Content Categorization &amp; Organization</B></h5>
<P>This 
is a facility to categorize and reference or store various forms of 
content, structured or unstructured.  This may include user or content 
profiles, live chat text, email, web sites, documents (text, Word, PDF, 
etc), news feeds and other textual content as unstructured, or semi-structured 
data, and database or organized file data as structured data.&nbsp;
</P>
<P>Tools for the input of this 
content should include manual targeting to specific pieces of 
content, and general spider tools such as those that follow web or other 
content links.&nbsp;</P>
<P>The tools automatically induce 
attributes, and use existing attributes, to classify the content, describe 
concepts in it, or create new attributes for groups of content.&nbsp;The output of the process may 
include content attributes or other meta information about the content such as
rules or constraints, 
or association links with other related content.  Manual overrides or 
tweaking of these links or meta information should be possible.</P>
<h5><B>Expert 
Identification / Person Classification</B></h5>
<P>These 
tools operate on user profiles and other user information such as authored 
or viewed content to isolate knowledge clusters of individuals.  With 
this information an appropriate resource can be found to address a specific 
issue or set of issues.&nbsp;</P>
<P>The user information that results 
from these processes can also be used to group users and create communities 
and provide targeted content for individuals or groups of users on a 
push or pull basis.</P>
<h5><B>Knowledge 
Presentation </B></h5>
<H5><I>Knowledge 
Visualization</I></H5>
<P>Knowledge 
visualization tools may include features such as viewing knowledge clustering 
frequency charts and knowledge association graphs or maps.  These knowledge 
graphs can be loosely formatted, or organized into tree-like hierarchies.  </P>
<H5><I>Knowledge 
Viewing</I></H5>
<P>This 
is a general tool for knowledge viewing.  It may organize the knowledge 
hierarchically using iconic representations with links to the actual 
knowledge, or provide various search options with links and short content 
descriptions as results, or whatever tool that may be available for 
general content browsing.  This may include personalization features 
that tailor content based on user profile information.  The output may 
be available in an application or as web based information.</P>
<h5><B>Automated 
Applications</B></h5>
<H5><I>Real 
Time Cross Reference</I></H5>
<P>These 
applications monitor content that is being viewed or created and offers 
links or references to related content in real time.</P>
<H5><I>New 
Content Dissemination</I></H5>
<P>These 
applications monitor and classify new content and send it to users who 
have subscribed to that type of content.  The new content may include news feeds, 
updated web pages, email messages, internal documents, etc.&nbsp;</P>
<hr>
<h3><a name="Basic Technology Components">Basic Technology Components</a></h3>
<hr>
<h4><a name="Foundation Technology">Foundation Technology</a></h4>
<ul>
  <li>Operating System
  <li>JVM &amp; J2EE App Server
  <li>Naming &amp; Directory (LDAP)
  <li>Relational Database (RDBMS)
</ul>
<hr>
<h4><a name="Security">Security</a></h4>
<P>Security 
features should include policy options for multiple types of entities 
including users, groups, and roles.  Multiple levels of groups and roles 
should also be supported.  Users should be able to exist in multiple 
groups and role categories.</P>
<P>Security 
policies should be able to flexibly apply to various levels of data and
functional granularity.  It 
should be possible to associate any type of user entity with each level 
of data granularity.</P>
<hr>
<h4><a name="Human Communication">Human Communication</a></h4>
<hr>
<h4><a name="Integration &amp; Connection">Integration &amp; Connection</a></h4>
<p>Integration and connection tools serve to purposes: to get access to data
from other applications, and to allow other applications to access data from
this application.&nbsp; General tools here include EJB calls, JMS, SOAP (and
other similar protocols), general XML passing, connector packages, and in
certain cases custom code.</p>
<hr>
<h4><a name="Development Tools">Development Tools</a></h4>
<hr>
<h4><a name="Quality Assurance">Quality Assurance</a></h4>
<ul>
  <li>Quality Testing
  <li>Usability Testing
  <li>Management &amp; Monitoring
  <li>Load Balancing/High Availability
</ul>


    

    
  

</body></html>

